{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f",
   "display_name": "Python 3.8.8 64-bit ('env_conda_1': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import time as time\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "source": [
    "# Web Scraping\n",
    "We are going to gather our data while putting minimal pressure on the target website's servers. We will use www.rev.com/ which has many transcripts available. I will mostly focus on the transcripts of Biden and Trump campaign speeches, before the 2020 election"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's give our program some fake credentials to make it appear like a real person is using it\n",
    "headers= {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.9,fr;q=0.8,ro;q=0.7,ru;q=0.6,la;q=0.5,pt;q=0.4,de;q=0.3',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'}\n",
    "\n",
    "# I found that more training data doesn't necessarily mean better quality, so we will try with less (~200,000 character training set) while increasing the number of epochs to train:\n",
    "url_list=[\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-election-day-remarks-transcript-scranton-pa',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-kamala-harris-election-day-eve-rally-speech-transcript-november-2',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-event-speech-transcript-pittsburgh-pa-november-2',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-speech-beaver-county-pennsylvania-november-2',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-drive-in-rally-speech-transcript-cleveland-november-2',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-event-speech-transcript-philadelphia-november-1',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-barack-obama-campaign-event-speech-transcript-flint-mi-october-31',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-speech-transcript-milwaukee-wisconsin-october-30',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-event-speech-transcript-st-paul-minnesota-october-30',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-event-speech-transcript-des-moines-iowa-october-30',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-rally-speech-transcript-tampa-fl-october-29',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-drive-in-rally-speech-transcript-broward-county-fl-october-29',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-speech-transcript-atlanta-georgia-october-27',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-speech-transcript-warm-springs-ga-october-27',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-north-carolina-speech-transcript-october-18',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-detroit-speech-transcript-october-16',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-speech-cincinnati-museum-center-transcript-october-12',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-mobilization-campaign-event-miramar-florida-transcript-october-13',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-las-vegas-speech-transcript-october-9',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-community-center-visit-las-vegas-transcript-october-9',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-kamala-harris-campaign-event-phoenix-az-transcript-october-8',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-miami-campaign-speech-transcript-october-5',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-campaign-speech-transcript-october-3',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-train-tour-speech-transcript-cleveland-ohio-september-30',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-train-tour-campaign-speech-transcript-alliance-ohio-september-30',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-remarks-transcript-september-26-us-conference-of-mayors',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-philadelphia-speech-transcript-sept-20-accuses-trump-republicans-of-abuse-of-power-over-scotus',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-cnn-town-hall-fracking-has-to-continue-transcript-september-17',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-pittsburgh-speech-transcript-august-31',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-and-kamala-harris-speech-transcript-august-12-first-campaign-event-as-running-mates',\n",
    "    'https://www.rev.com/blog/transcripts/joe-biden-speech-transcript-warren-michigan-september-9'\n",
    "]"
   ]
  },
  {
   "source": [
    "### Our web-scraping function which returns the statements made solely by Joe Biden:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeches(url_list):\n",
    "    n=0\n",
    "    global string_all #A global variable containing all of strings, for greater flexibility in the future.\n",
    "    string_all=''\n",
    "    string_Biden='' #This is where we will store Biden's speeches\n",
    "\n",
    "    for url in url_list:\n",
    "        time.sleep(abs(np.random.normal(40,10))) #I don't want to add extra pressure on their servers. I also don't want anyone else running this code to get their IP address blocked, so I\n",
    "                                                  #added randomness to the timing of our execution via a normal distribution\n",
    "\n",
    "        html=requests.get('{}'.format(url), headers=headers).text #Get the html data\n",
    "        soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        #Let's now get the main blocks of data which are the transcripts:\n",
    "        transcript=soup.find_all('p')\n",
    "\n",
    "        #If the block of text starts with some variation of Joe Biden:, then:\n",
    "        transcript_Biden=[statement for statement in transcript if ('Joe Biden:' in statement.text[:35]) | \n",
    "                ('Joseph R Biden:' in statement.text[:30]) | ('Joseph R. Biden:' in statement.text[:35])] \n",
    "        \n",
    "        #Use regex to split the sentences on \\n which proceeds \"Biden:\", retrieve Biden's speech:\n",
    "        for statement in transcript_Biden:\n",
    "            string_Biden+='\\n '+re.split('(\\n)', statement.text)[-1] \n",
    "        for statement in transcript:\n",
    "            string_all+= statement.text\n",
    "        n+=1\n",
    "        if n%3==0:\n",
    "            print('{}% completed'.format( round( 100*((url_list.index(url)+1)/len(url_list)), 1) ))\n",
    "    print('Done.')\n",
    "    return string_Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.1% completed\n",
      "46.2% completed\n",
      "69.2% completed\n",
      "92.3% completed\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "string_Biden=get_speeches(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also load in the text directly, which I saved from earlier\n",
    "def load_Biden_str():\n",
    "    global string_Biden\n",
    "    string_Biden=''\n",
    "    with open('text_Biden.txt','r') as file:\n",
    "        list_Biden=file.readlines()\n",
    "    for line in list_Biden:\n",
    "        string_Biden+=line\n",
    "\n",
    "def write_Biden_str():\n",
    "    global string_Biden\n",
    "    with open('text_Biden.txt', 'w') as file:\n",
    "        file.write(string_Biden)"
   ]
  },
  {
   "source": [
    "## Training our RNN on the data\n",
    "We create a keras Tokenizer which will create a unique number for every word seen in the data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts([string_Biden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[484, 4335]]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"Example input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['example input']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[484, 4335]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size=sum(tokenizer.word_counts.values()) #Use for word-level\n",
    "#dataset_size = tokenizer.document_count # total number of characters. Use for char-level"
   ]
  },
  {
   "source": [
    "## Preprocessing Step\n",
    "In order to train our model, we have to create pairs of sets of words. The first set of every pair will be 100 words long (training set), and the second set will contain one word only. Our model will therefore have to determine that, given an input of 100 words (more words for longer term memory), what it expects the output word to be. We will shuffle our sets of data to create an i.i.d dataset. 100 n_steps represents a fairly long memory on which our model will be trained on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([string_Biden])) - 1\n",
    "train_size = dataset_size * 100 // 100 #We will not be using the validation set for the time being.\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "\n",
    "n_steps = 100 \n",
    "window_length = n_steps + 1 # target = input shifted 1 word ahead\n",
    "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(7600).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1) #Add prefetching"
   ]
  },
  {
   "source": [
    "## Model training\n",
    "We will use a GRU layer instead of LSTM since the GRU is much simpler (and therefore much less memory intensive) and provides very similar precision. Dropout has been shown to improve performance in select cases (especially when using Monte Carlo), and to greatly reduce overfitting. The output will be a softmax function and will have an array of probabilities for each number/word. We will use Adam optimization which uses momentum-like properties to speed up our gradient descent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time=datetime.now()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
    "                    epochs=10)\n",
    "\n",
    "time_end=datetime.now()-first_time\n",
    "print(time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('BidenBot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}