{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f",
   "display_name": "Python 3.8.8 64-bit ('env_conda_1': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "import re\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Loading in our model and tokenizer:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('BidenBot_word_lvl.h5')\n",
    "\n",
    "#Pickling has some security issues so we will retrain our tokenizer on the same dataset:\n",
    "def get_tokenizer():\n",
    "    global tokenizer\n",
    "    global max_id\n",
    "    global dataset_size\n",
    "\n",
    "    string_Biden='' #We will store the Biden dataset here\n",
    "\n",
    "    with open('text_Biden.txt','r') as file:\n",
    "        list_Biden=file.readlines()\n",
    "\n",
    "    for line in list_Biden:\n",
    "        string_Biden+=line\n",
    "\n",
    "    tokenizer = keras.preprocessing.text.Tokenizer(char_level=False)\n",
    "    tokenizer.fit_on_texts([string_Biden])\n",
    "\n",
    "    max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "    dataset_size = tokenizer.document_count # total number of characters\n",
    "\n",
    "get_tokenizer()"
   ]
  },
  {
   "source": [
    "## Data Preprocessing:\n",
    "Similar to what we did for training our RNN model, we will need to use tokenizer to create a list of sequences represented by a sparse one-hot tensor object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "source": [
    "## Creating the output:\n",
    "We will call the complete_text func. with a text variable which acts to initialize our string. \n",
    "For the number of words requested (n_words), we will create said number of characters by predicting the next word, n_words times. To create unique strings, we will use a log function on our predicted probabilities before applying a tf.random.categorical function which uses such values in order to generate a set of values (in this case we only generate one sample). I will show you an example of how temperature affects our output:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#Generate a random value 40 times\n",
    "temperature=.1\n",
    "probability=.9\n",
    "tf.random.categorical([[np.log(probability)/temperature, np.log(1-probability)/temperature]], num_samples=40).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "temperature=5\n",
    "probability=.9\n",
    "tf.random.categorical([[np.log(probability)/temperature, np.log(1-probability)/temperature]], num_samples=40).numpy()"
   ]
  },
  {
   "source": [
    "So as you can see, we are able to directly make our model generate more random output just by increasing the temperature values. Let's apply this below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_words=100, temperature=1):\n",
    "    for i in range(n_words):\n",
    "        text += next_word(text, temperature)+' '\n",
    "    return text\n",
    "def next_word(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    word_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(word_id.numpy())[0]"
   ]
  },
  {
   "source": [
    "We will now create functions necessary to run our tkinter code. This will call complete_text(), add new lines with add_n_lines(), so as to not have the output run off the tk window, and capitalize every letter that comes after the end of a sentence. click_generate() will activate when we press the button on our tk window."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_generate(entry):\n",
    "    label2['text']=output(entry)\n",
    "\n",
    "def replace_lower_case(speech):\n",
    "    #We will replace all lower case characters after period_space, period_question mark, period_exclamation.\n",
    "    indeces=[i.end() for i in re.finditer('(\\. *)|(\\? *)|(\\! *)', speech)] #Get the indices of the char proceeding a period,...\n",
    "    for i in indeces:\n",
    "        #Separate into three pieces and capitalize the letter. If not a letter then continue,\n",
    "        try:\n",
    "            string_pre=speech[:(i)]\n",
    "            char_Upper=speech[i].capitalize() \n",
    "            string_post=speech[(i+1):]\n",
    "            speech=string_pre+char_Upper+string_post\n",
    "        except Exception as x:\n",
    "            continue\n",
    "    return speech\n",
    "\n",
    "def add_n_lines(speech):\n",
    "    #Add new lines:\n",
    "    string=textwrap.dedent(speech)\n",
    "    speech='\\n'.join(i for line in string.splitlines() for i in textwrap.wrap(line, width=44))\n",
    "    return speech\n",
    "\n",
    "def output(entry):\n",
    "    if len(entry)==0:\n",
    "        return 'Must include text' #If no input given\n",
    "    elif entry[-1]!=' ':\n",
    "        return 'Must end with a space'\n",
    "    #You can play around with the temperature yourself. Anything between .01 and 1.0 will give you a relatively good output, with a higher value being more 'random', and with a lower value           allowing the model to more likely choose the word arrangement that it believes to be correct (which often leads to repetition unfortunately)!\n",
    "    speech=complete_text(entry,n_words=84, temperature=0.27)\n",
    "    speech=replace_lower_case(speech)\n",
    "    speech=add_n_lines(str(speech))\n",
    "\n",
    "    speech+= '\\n \\n \\t \\t\\t - BidenBot' #Add a signature\n",
    "    print(speech)\n",
    "    return speech"
   ]
  },
  {
   "source": [
    "Running this may take several minutes, depending on what hardware you are using (especially if you switched to char level encoding)!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Run:\n",
    "Let's now create our window. I have included images for the background, trying to keep it from being political despite the political nature of the training data. Sometimes, if the image doesn't load, you have to close the window and run the code again."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello pittsburgh it’s true honk i have to\n",
      "you going to pay your mortgage pay your rent\n",
      "worried about the poison in the air you\n",
      "breathe the water you drink worried about\n",
      "your civil rights even your basic right to\n",
      "dignity which is under attack with this\n",
      "administration kamala harris has had your\n",
      "back and now we have to have her back she’s\n",
      "going to stand with me in this campaign and\n",
      "all of us are going to stand up for her on\n",
      "january 20\n",
      " \n",
      " \t \t\t - BidenBot\n",
      "Donald trump is going to meet the challenge\n",
      "of climate crisis donald trump calls it a\n",
      "hoax i call it about our health and the\n",
      "ability to create millions of good paying\n",
      "jobs right here in western pennsylvania we\n",
      "can combat climate change with american\n",
      "ingenuity and manufacturing creating\n",
      "millions of new high paying union jobs let\n",
      "me be clear i will not ban fracking in\n",
      "pennsylvania i’ll protect those jobs period\n",
      "no matter what donald trump says but i tell\n",
      "you what i will\n",
      " \n",
      " \t \t\t - BidenBot\n",
      "Donald trump is going to be the first\n",
      "president in 90 years who’s going to finish\n",
      "with his four years in office with fewer\n",
      "jobs under his leadership than when he\n",
      "started as president and black unemployment\n",
      "remains too high too many black businesses\n",
      "are shuttered for good black owned\n",
      "businesses are shutting down twice as fast\n",
      "as other businesses and business communities\n",
      "of color have shuttered because they didn’t\n",
      "get the help the money that congress has\n",
      "passed congress passed over 2 trillion you\n",
      " \n",
      " \t \t\t - BidenBot\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root=tk.Tk()\n",
    "\n",
    "canvas=tk.Canvas(root, height=750, width=540)\n",
    "canvas.pack()\n",
    "\n",
    "try:\n",
    "    background_image=tk.PhotoImage(file='Biden.png')\n",
    "    background_label=tk.Label(root, image=background_image)\n",
    "    background_label.place(relwidth=1, relheight=1)\n",
    "\n",
    "except Exception as x:\n",
    "    print(x)\n",
    "\n",
    "frame=tk.Frame(root, bg='#1a1aff', bd=4)\n",
    "frame.place(relx=0.5, rely=0.02, relwidth=.9, relheight=0.05, anchor='n')\n",
    "\n",
    "label1=tk.Label(frame, text='Start output with:', bg='#e6ffff', font=30)\n",
    "label1.place(relx=0, rely=0, relwidth=0.3, relheight=1)\n",
    "\n",
    "entry=tk.Entry(frame, bg='#e6ffff', font=50)\n",
    "entry.place(relx=0.3, rely=0, relwidth=.5, relheight=1)\n",
    "\n",
    "button=tk.Button(frame, text='Generate', bg='blue', fg='blue', font=78, command=lambda: click_generate(entry.get()))\n",
    "button.place(relx=.8, rely=0, relwidth=.2, relheight=1)\n",
    "\n",
    "bottom_frame=tk.Frame(root, bg='#1a1aff', bd=4)\n",
    "bottom_frame.place(relx=0.5, rely=.2, relwidth=.8, relheight=.4, anchor='n')\n",
    "\n",
    "label2=tk.Label(bottom_frame, bg='#e6ffff', font=('Microsoft Sans Serif', 20), anchor='nw', justify='left')\n",
    "label2.place(relwidth=1, relheight=1)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}