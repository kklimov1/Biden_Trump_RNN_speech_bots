{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f",
   "display_name": "Python 3.8.8 64-bit ('env_conda_1': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "import re\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Loading in our model and tokenizer:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('BidenBot.h5')\n",
    "\n",
    "#Pickling has some security issues so we will retrain our tokenizer on the same dataset:\n",
    "def get_tokenizer():\n",
    "    global tokenizer\n",
    "    global max_id\n",
    "    global dataset_size\n",
    "\n",
    "    string_Biden='' #We will store the Biden dataset here\n",
    "\n",
    "    with open('text_Biden.txt','r') as file:\n",
    "        list_Biden=file.readlines()\n",
    "\n",
    "    for line in list_Biden:\n",
    "        string_Biden+=line\n",
    "\n",
    "    tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "    tokenizer.fit_on_texts(string_Biden)\n",
    "\n",
    "    max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "    dataset_size = tokenizer.document_count # total number of characters\n",
    "\n",
    "get_tokenizer()"
   ]
  },
  {
   "source": [
    "## Data Preprocessing:\n",
    "Similar to what we did for training our RNN model, we will need to use tokenizer to create a list of sequences represented by a sparse one-hot tensor object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "source": [
    "## Creating the output:\n",
    "We will call the complete_text func. with a text variable which acts to initialize our string. \n",
    "For the number of characters requested (n_chars), we will create said number of characters by predicting the next char, n_chars times. To create unique strings, we will use a log function on our predicted probabilities before applying a tf.random.categorical function which uses such values in order to generate a set of values (in this case we only generate one sample). I will show you an example of how temperature affects our output:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#Generate a random value 40 times\n",
    "temperature=.1\n",
    "probability=.9\n",
    "tf.random.categorical([[np.log(probability)/temperature, np.log(1-probability)/temperature]], num_samples=40).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "temperature=5\n",
    "probability=.9\n",
    "tf.random.categorical([[np.log(probability)/temperature, np.log(1-probability)/temperature]], num_samples=40).numpy()"
   ]
  },
  {
   "source": [
    "So as you can see, we are able to directly make our model generate more random output just by increasing the temperature values. Let's apply this:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for i in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text\n",
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "source": [
    "We will now create functions necessary to run our tkinter code. This will call complete_text(), add new lines with add_n_lines(), so as to not have the output run off the tk window, and capitalize every letter that comes after the end of a sentence. click_generate() will activate when we press the button on our tk window."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_generate(entry):\n",
    "    label2['text']=output(entry)\n",
    "\n",
    "def replace_lower_case(speech):\n",
    "    #We will replace all lower case characters after period_space, period_question mark, period_exclamation.\n",
    "    indeces=[i.end() for i in re.finditer('(\\. *)|(\\? *)|(\\! *)', speech)] #Get the indices of the char proceeding a period,...\n",
    "    for i in indeces:\n",
    "        #Separate into three pieces and capitalize the letter. If not a letter then continue,\n",
    "        try:\n",
    "            string_pre=speech[:(i)]\n",
    "            char_Upper=speech[i].capitalize() \n",
    "            string_post=speech[(i+1):]\n",
    "            speech=string_pre+char_Upper+string_post\n",
    "        except Exception as x:\n",
    "            continue\n",
    "    return speech\n",
    "\n",
    "def add_n_lines(speech):\n",
    "    #Add new lines:\n",
    "    string=textwrap.dedent(speech)\n",
    "    speech='\\n'.join(i for line in string.splitlines() for i in textwrap.wrap(line, width=47))\n",
    "    return speech\n",
    "\n",
    "def output(entry):\n",
    "    if len(entry)==0:\n",
    "        return 'Must include text' #If no input given\n",
    "\n",
    "    #You can play around with the temperature yourself. Anything between .01 and 1.0 will give you a relatively good output, with a higher value being more 'random', and with a lower value           allowing the model to more likely choose the letter arrangement that it believes to be correct (which often leads to repetition unfortunately)!\n",
    "    speech=complete_text(entry,n_chars=460, temperature=0.17)\n",
    "    speech=replace_lower_case(speech)\n",
    "    speech=add_n_lines(str(speech))\n",
    "\n",
    "    speech+= '\\n \\n \\t \\t\\t - BidenBot' #Add a signature\n",
    "    print(speech)\n",
    "    return speech"
   ]
  },
  {
   "source": [
    "## Running this may take several minutes, depending on what hardware you are using!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's now create our window. I have included images for the background, trying to keep it from being political despite the political nature of the training data. Sometimes, if the image doesn't load, you have to close the window and run the code again."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello it the state of americans have all seen\nthe pastpone. I’m going to shop and the reason\nwhen you say, i’m running as a proud democrat,\nbut i tell you what, the past seek with you.\nThat sense of empowerment with you. Thank you.\nThank you.\n thank you and thank you for the soul of the\npalllies families and surrendered to the moon\nin the state of americans have all seed the\nstate of americans have all see nothing. But i\ntell you what, the past say, “joey, and we\n \n \t \t\t - BidenBot\n"
     ]
    }
   ],
   "source": [
    "root=tk.Tk()\n",
    "\n",
    "canvas=tk.Canvas(root, height=750, width=540)\n",
    "canvas.pack()\n",
    "\n",
    "try:\n",
    "    background_image=tk.PhotoImage(file='Biden.png')\n",
    "    background_label=tk.Label(root, image=background_image)\n",
    "    background_label.place(relwidth=1, relheight=1)\n",
    "\n",
    "except Exception as x:\n",
    "    print(x)\n",
    "\n",
    "frame=tk.Frame(root, bg='#1a1aff', bd=4)\n",
    "frame.place(relx=0.5, rely=0.02, relwidth=.9, relheight=0.05, anchor='n')\n",
    "\n",
    "label1=tk.Label(frame, text='Start output with:', bg='#e6ffff', font=30)\n",
    "label1.place(relx=0, rely=0, relwidth=0.3, relheight=1)\n",
    "\n",
    "entry=tk.Entry(frame, bg='#e6ffff', font=50)\n",
    "entry.place(relx=0.3, rely=0, relwidth=.5, relheight=1)\n",
    "\n",
    "button=tk.Button(frame, text='Generate', bg='blue', fg='blue', font=78, command=lambda: click_generate(entry.get()))\n",
    "button.place(relx=.8, rely=0, relwidth=.2, relheight=1)\n",
    "\n",
    "bottom_frame=tk.Frame(root, bg='#1a1aff', bd=4)\n",
    "bottom_frame.place(relx=0.5, rely=.2, relwidth=.8, relheight=.4, anchor='n')\n",
    "\n",
    "label2=tk.Label(bottom_frame, bg='#e6ffff', font=('Microsoft Sans Serif', 20), anchor='nw', justify='left')\n",
    "label2.place(relwidth=1, relheight=1)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}