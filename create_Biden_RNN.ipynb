{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f",
   "display_name": "Python 3.8.8 64-bit ('env_conda_1': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e0a83d2837cbcebdc7f204a8b982de19d2adbcdceada914311d93b1426a5ff8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import time as time\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "source": [
    "# Web Scraping\n",
    "We are going to gather our data while putting minimal pressure on the target website's servers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's give our program some fake credentials to make it appear like a real person is using it\n",
    "headers= {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.9,fr;q=0.8,ro;q=0.7,ru;q=0.6,la;q=0.5,pt;q=0.4,de;q=0.3',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'}\n",
    "\n",
    "# These are the target url's which are mostly from rallys and speeches\n",
    "url_list=[\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-cpac-2021-speech-transcript',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-speech-transcript-departing-white-house-on-inauguration-day',\n",
    "    'https://www.rev.com/blog/transcripts/president-donald-trump-farewell-address-speech-transcript',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-second-video-speech-condemning-capitol-violence-transcript',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trumps-first-comments-since-capitol-riots-says-he-wants-no-violence',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-concedes-election-condemns-rioters-video-transcript-january-7',\n",
    "    'https://www.rev.com/blog/transcripts/trump-video-telling-protesters-at-capitol-building-to-go-home-transcript',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-speech-save-america-rally-transcript-january-6',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-dalton-georgia-senate-runoff-election',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-georgia-phone-call-transcript-brad-raffensperger-recording',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-hosts-operation-warp-speed-covid-19-vaccine-summit-transcript-december-8',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-georgia-rally-transcript-before-senate-runoff-elections-december-5',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-speech-on-election-fraud-claims-transcript-december-2',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-remarks-transcript-pennsylvania-republican-hearing-on-2020-election',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-white-house-press-conference-on-lowering-drug-prices-transcript',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-white-house-press-conference-as-election-counts-continue-transcript-november-5',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-kenosha-wi-november-2',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-scranton-pa-november-2',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-fayetteville-nc-november-2',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-rome-georgia-november-1',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-waterford-township-michigan-october-30',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-green-bay-wisconsin-october-30',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-tampa-fl-october-29',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-bullhead-city-az-october-28',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-omaha-ne-october-27',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-west-salem-wisconsin-october-27',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-lansing-michigan-october-27',\n",
    "    'https://www.rev.com/blog/transcripts/donald-trump-circleville-ohio-rally-speech-transcript-october-24'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our web-scraping function which returns the statements made solely by Donald Trump.\n",
    "def get_speeches(url_list):\n",
    "    global string_all #A global variable containing all of strings, for greater flexibility in the future.\n",
    "    string_all=''\n",
    "    string_Trump=''\n",
    "    for url in url_list:\n",
    "        time.sleep(abs(np.random.normal(28,24))) #I don't want to add extra pressure on their servers. I also don't want anyone else running this code to get their IP address blocked, so I\n",
    "                                                  #added randomness to the timing of our execution via a normal distribution\n",
    "\n",
    "        html=requests.get('{}'.format(url), headers=headers).text #Get the html data\n",
    "        soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        #Let's now get the main blocks of data which are the transcripts:\n",
    "        transcript=soup.find_all('p')\n",
    "\n",
    "        #If the block of text starts with some variation of Donald Trump:, then:\n",
    "        transcript_DT=[statement for statement in transcript if ('Donald Trump:' in statement.text[:30]) | \n",
    "                ('President Trump:' in statement.text[:30]) | ('Donald J. Trump:' in statement.text[:35])] \n",
    "        \n",
    "        for statement in transcript_DT:\n",
    "            string_Trump+='\\n '+re.split('(\\n)', statement.text)[-1] #Use regex to split the sentences on \\n which proceeds Trump:, retrieve Trump's speech. Example given below\n",
    "        for statement in transcript:\n",
    "            string_all+= statement.text\n",
    "\n",
    "        print('{}% completed'.format( round( 100*((url_list.index(url)+1)/len(url_list)), 1) ))\n",
    "    return string_Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.6% completed\n",
      "7.1% completed\n",
      "10.7% completed\n",
      "14.3% completed\n",
      "17.9% completed\n",
      "21.4% completed\n",
      "25.0% completed\n",
      "28.6% completed\n",
      "32.1% completed\n",
      "35.7% completed\n",
      "39.3% completed\n",
      "42.9% completed\n",
      "46.4% completed\n",
      "50.0% completed\n",
      "53.6% completed\n",
      "57.1% completed\n",
      "60.7% completed\n",
      "64.3% completed\n",
      "67.9% completed\n",
      "71.4% completed\n",
      "75.0% completed\n",
      "78.6% completed\n",
      "82.1% completed\n",
      "85.7% completed\n",
      "89.3% completed\n",
      "92.9% completed\n",
      "96.4% completed\n",
      "100.0% completed\n"
     ]
    }
   ],
   "source": [
    "string_Trump=get_speeches(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also load in the text directly, which I saved from earlier\n",
    "def load_Trump_str():\n",
    "    global string_Trump\n",
    "    string_Trump=''\n",
    "    with open('text_Donald.txt','r') as file:\n",
    "        list_Trump=file.readlines()\n",
    "    for line in list_Trump:\n",
    "        string_Trump+=line\n",
    "\n",
    "def write_Trump_str():\n",
    "    global string_Trump\n",
    "    with open('text_Donald.txt', 'w') as file:\n",
    "        file.write(string_Trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(string_Trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[', n s r t']"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size = tokenizer.document_count # total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([string_Trump])) - 1\n",
    "train_size = dataset_size * 95 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "\n",
    "n_steps = 147 #He uses quite lengthy sentences to make his point, so I will set this higher to account for more long term memory\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(7600).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 147, 61) (32, 147)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "30962/30962 [==============================] - 13575s 438ms/step - loss: 1.5204\n",
      "Epoch 2/10\n",
      "30962/30962 [==============================] - 13923s 450ms/step - loss: 1.2908\n",
      "Epoch 3/10\n",
      "30962/30962 [==============================] - 13993s 452ms/step - loss: 1.2624\n",
      "Epoch 4/10\n",
      "30962/30962 [==============================] - 13996s 452ms/step - loss: 1.2479\n",
      "Epoch 5/10\n",
      "30962/30962 [==============================] - 14021s 453ms/step - loss: 1.2379\n",
      "Epoch 6/10\n",
      "30962/30962 [==============================] - 14032s 453ms/step - loss: 1.2323\n",
      "Epoch 7/10\n",
      "30962/30962 [==============================] - 14040s 453ms/step - loss: 1.2274\n",
      "Epoch 8/10\n",
      "30962/30962 [==============================] - 14103s 455ms/step - loss: 1.2239\n",
      "Epoch 9/10\n",
      "30962/30962 [==============================] - 14071s 454ms/step - loss: 1.2211\n",
      "Epoch 10/10\n",
      "30962/30962 [==============================] - 14040s 453ms/step - loss: 1.2182\n",
      "1 day, 14:49:53.895391\n"
     ]
    }
   ],
   "source": [
    "first_time=datetime.now()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
    "                    epochs=10)\n",
    "\n",
    "time_end=datetime.now()-first_time\n",
    "print(time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('TrumpBot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "X_new = preprocess([\"How are yo\"])\n",
    "#Y_pred = model.predict_classes(X_new)\n",
    "Y_pred = np.argmax(model(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 1, 0, 2, 1,\n",
       "        0, 1, 2, 1, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2]])"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "next_char(\"How are yo\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_t=complete_text(\"Thank\",n_chars=400, temperature=0.2)\n",
    "print(speech_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thank you very much. and i want to thank you than a journey will be a lot of things that we did a good job. i wouldn’t have run. we had a good job. i want to thank you were that nobody else is the state of our country. i said, “well, he was the state of our country. i said, “what the hell is the crimisal country. he wants to complete what it’s going to be that the most important election in the world. \n"
     ]
    }
   ],
   "source": [
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Biden has to come back. we have the criminals. the fake news and a half of the world. and it’s amazing the biden and a half. you know what\n"
     ]
    }
   ],
   "source": [
    "speech_t=complete_text(\"Biden\",n_chars=133, temperature=0.2)\n",
    "print(speech_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}